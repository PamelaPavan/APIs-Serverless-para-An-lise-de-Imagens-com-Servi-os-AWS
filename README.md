<h1 align="center">Desenvolvimento de APIs Serverless para AnÃ¡lise de Imagens com ServiÃ§os AWS</h1>
<h2 align="center">ImplementaÃ§Ã£o de Rotas para AnÃ¡lise de EmoÃ§Ãµes Humanas e IdentificaÃ§Ã£o de Animais e RaÃ§as Utilizando Amazon Rekognition e Monitoramento com Amazon CloudWatch</h2>

![Logo](https://s3.sa-east-1.amazonaws.com/remotar-assets-prod/company-profile-covers/cl7god9gt00lx04wg4p2a93zt.jpg)

[![AWS](https://img.shields.io/badge/AWS-Cloud-yellow.svg)](https://aws.amazon.com/)
[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Serverless](https://img.shields.io/badge/Serverless-Framework-orange.svg)](https://www.serverless.com/)

## ğŸ“Œ Ãndice
1. [Objetivo do Projeto](#-objetivo-do-projeto)
2. [Desenvolvimento do projeto](#-desenvolvimento)
3. [Estrutura de pastas](#-estrutura-de-pastas)
4. [Arquitetura AWS](#ï¸-arquitetura-aws)
5. [Como usar o sistema](#-como-instalar-e-usar-o-sistema)
6. [Tecnologias utilizadas](#-tecnologias-utilizadas)
7. [Dificuldades encontradas](#ï¸-dificuldades-encontradas)
8. [Trabalhos Futuros](#-trabalhos-futuros)
9. [Autores](#-autores)

## ğŸ“– Objetivo do Projeto
Criar APIs, com o framework "serverless", que utiliza os serviÃ§os Amazon Rekognition para anÃ¡lise de imagens, Amazon Bedrock para geraÃ§Ã£o de conteÃºdo baseado em IA e Amazon CloudWatch para monitoramento e registro de logs.

## ğŸ¯ Desenvolvimento

A aplicaÃ§Ã£o foi desenvolvida utilizando o framework serverless para criar duas rotas para a nossa API que irÃ£o rodar o Amazon Rekognition para extrair tags de imagens postadas no s3 e o Amazon Bedrock para gerar conteÃºdo. 

Parte 1: Foram implementadas as especificaÃ§Ãµes pediddas. Upload manual de imagens para o s3, definiÃ§Ã£o do bounding box das faces encontradas e a emoÃ§Ã£o principal classificada pelo modelo.

Parte 2: Foram implementadas as especificaÃ§Ãµes pediddas. Da mesma forma, upload manual de imagens para o s3. Depois, Ã© feita uma chamada do Rekognition para identificaÃ§Ã£o de labels e, caso seja encontrada uma face, fazemos uma segunda chamada ao Rekognition para indentificar os features e emoÃ§Ãµes da face, por fim, utilizamos o Bedrock para gerar dicas sobre a(s) raÃ§a(s) do pet encontrado nos labels.

## ğŸ“‚ Estrutura de pastas
 
```md
sprint-8-pb-aws-abril
â”œâ”€â”€ assets
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ visao-computacional
â”‚   |   â”œâ”€â”€ errors
â”‚   |   â”‚   â”œâ”€â”€ __init__.py
â”‚   |   â”‚   â”œâ”€â”€ bad_request_errors.py
â”‚   |   â”‚   â”œâ”€â”€ base_error.py
â”‚   |   â”‚   â””â”€â”€ internal_server_error.py
â”‚   |   â”œâ”€â”€ handlers
â”‚   |   â”‚   â”œâ”€â”€ __init__.py
â”‚   |   â”‚   â”œâ”€â”€ create_response.py
â”‚   |   â”‚   â”œâ”€â”€ handle_bad_request.py
â”‚   |   â”‚   â””â”€â”€ handle_internal_server_error.py
â”‚   |   â”œâ”€â”€ rekognition
â”‚   |   â”‚   â”œâ”€â”€ __init__.py
â”‚   |   â”‚   â”œâ”€â”€ rekognition_image_detection.py
â”‚   |   â”‚   â””â”€â”€ rekognition_objects.py
â”‚   |   â”œâ”€â”€ routes
â”‚   |   â”‚   â”œâ”€â”€ __init__.py
â”‚   |   â”‚   â”œâ”€â”€ health.py
â”‚   |   â”‚   â”œâ”€â”€ v1_description.py
â”‚   |   â”‚   â”œâ”€â”€ v1_vision.py
â”‚   |   â”‚   â”œâ”€â”€ v2_description.py
â”‚   |   â”‚   â””â”€â”€ v2_vision.py
â”‚   |   â”œâ”€â”€ tests
â”‚   |   â”‚   â”œâ”€â”€ test_errors.py
â”‚   |   â”‚   â”œâ”€â”€ test_handlers.py
â”‚   |   â”‚   â””â”€â”€ test_utils.py
â”‚   |   â””â”€â”€ utils
â”‚   |       â”œâ”€â”€ __init__.py
â”‚   |       â”œâ”€â”€ bedrock.py
â”‚   |       â”œâ”€â”€ labels.py
â”‚   |       â”œâ”€â”€ parse_body.py
â”‚   |       â””â”€â”€ v1_response.py
|   â”œâ”€â”€ conftest.py
|   â”œâ”€â”€ serverless.yml
|   â””â”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ images.md
â””â”€â”€ README.md
```


## ğŸ—ï¸ Arquitetura AWS
![Imagem|Diagrama](assets/arquitetura-base.jpg)

## ğŸš€ Como instalar e usar o sistema

1. Verifique se vc tem o python instalado. Mais informaÃ§Ãµes [aqui](https://www.python.org/) 

2. Instale o framework serverless em seu computador. Mais informaÃ§Ãµes [aqui](https://www.serverless.com/framework/docs/getting-started)

```bash
npm install -g serverless
```

3. Gere suas credenciais (AWS Acess Key e AWS Secret) na console AWS pelo IAM. Mais informaÃ§Ãµes [aqui](https://www.serverless.com/framework/docs/providers/aws/guide/credentials/)

4. Depois de clonado o repo e instaldo o serverless, temos que navegar para a pasta da api:

```bash
git clone htt://.....
cd sprint-8-pb-aws-abril
```

5. Instalr os plugins para rodar o projeto em modo local:

```bash
cd src/visao-computacional
serverless plugin install -n serverless-dotenv-plugin
```

6. Nessa altura, Ã© preciso configurar o seu arquivo .env. Crie um arquivo .env no foler visao-computacional, onde se encontra o arquivo .evn.example.
Preencha com os dados do seu env.

7. Com o env configurado, podemos agora rodar em modo local e testar os nossos endpoints:

- Para testar uma rota especÃ­fica, por exemplo:

```bash
serverless invoke local --function hello
```
- Para fazer o deploy do projeto:

```bash
serverless deploy
```

- Para fazer o deploy e ver as informaÃ§Ãµes adicionais:

```bash
serverless deploy --verbose
```

- Para fazer o deploy de uma funÃ§Ã£o especÃ­fica, por exemplo:

```bash
serverless deploy function -f functionName
```

8. Para rodar os testes unitÃ¡rios:

```bash
pytest tests/*.py -v -s
```

## ğŸ” Nossas rotas

Ã‰ possÃ­vel utilizar nosso sistema em produÃ§Ã£o a partir dessas rotas utilizando, por exemplo, o Postman:

**https://jntnuwkzuj.execute-api.us-east-1.amazonaws.com/v1/vision**

JSON de exemplo para post:
```json
{  
   "bucket": "vision-image-files-bucket",  
   "imageName": "two-faces.jpg"  
} 
```

**https://jntnuwkzuj.execute-api.us-east-1.amazonaws.com/v2/vision**

```json
{  
   "bucket": "vision-image-files-bucket",  
   "imageName": "dog.jpg"  
} 
```

Ou utilizando o comando curl:

```bash
curl -i -X POST -H 'Content-Type: application/json' -d '{"bucket": "vision-image-files-bucket", "imageName": "two-faces.jpg"}' https://jntnuwkzuj.execute-api.us-east-1.amazonaws.com/v1/vision
v1/vision
```

```bash
curl -i -X POST -H 'Content-Type: application/json' -d '{"bucket": "vision-image-files-bucket", "imageName": "dog.jpg"}' https://jntnuwkzuj.execute-api.us-east-1.amazonaws.com/v1/vision
v2/vision
```

[**Lista de imagens por rotas**](images.md)

## ğŸ’» Tecnologias utilizadas

### AWS
- **S3:** utilizado para armazenar as imagens que serÃ£o analisadas pelo Amazon Rekognition. As imagens sÃ£o carregadas manualmente no bucket especificado e os URLs sÃ£o usados nas requisiÃ§Ãµes da API.
- **CloudWatch:** utilizado para registrar os logs das chamadas das funÃ§Ãµes Lambda.
- **Amazon Rekognition:** utilizado para detectar e analisar as emoÃ§Ãµes nas faces presentes nas imagens. TambÃ©m foi utilizado para identificar a presenÃ§a de pets.
- **Amazon Bedrock:** utilizado para gerar conteÃºdo com base nas informaÃ§Ãµes obtidas pelo Rekognition. Quando um pet Ã© detectado na imagem, o Bedrock gera dicas relacionadas ao pet, incluindo nÃ­vel de energia, necessidades de exercÃ­cios, temperamento, cuidados e problemas de saÃºde comuns.

### Geral
- **Python:** a aplicaÃ§Ã£o foi desenvolvida em Python, seguindo a estrutura base disponibilizada. Utilizamos bibliotecas especÃ­ficas para integraÃ§Ã£o com os serviÃ§os AWS.
- **Postman:** utilizado para testar as rotas da API. Foram realizados testes para garantir que as rotas GET e POST retornassem os resultados esperados, conforme especificado.
- **Framework Serverless:** utilizado para gerenciar a infraestrutura como cÃ³digo. AtravÃ©s do Serverless, foi possÃ­vel configurar e fazer o deploy das funÃ§Ãµes Lambda e dos recursos necessÃ¡rios na AWS.
- **Boto3:** utilizada como AWS SDK para Python, facilitando a comunicaÃ§Ã£o entre o cÃ³digo Python e os serviÃ§os AWS. Foi utilizada para interagir com o S3, Rekognition e CloudWatch.


## ğŸ› ï¸ Dificuldades encontradas

- Respostas inconsistentes do Bedrock no caso de mais de uma raÃ§a encontrada. As vezes ele da dicas sobre as duas, as vezes ele da dica sobre uma sÃ³.

- Impossibilidade de quebra de linhas , '\n', na resposta do JSON.

- Retorno quando nÃ£o encontrada a face. No python Ã© utilizado o None para representar um objeto nulo. Quando os retornos do JSON sÃ£o setados como None, a configuraÃ§Ã£o final seria algo como `"Height": null` e nÃ£o `"Height": Null`. Optamos por utilizar o None ao invÃ©s de setar o atributo do JSON para uma string "Null".

## âš™ Trabalhos futuros

- Implementar uma melhor forma de filtragem e seleÃ§Ã£o de raÃ§as encontradas, talvez o uso de collections.

- Terminar e finalizar o deploy do frontend.

- Entendemos que o upload manual Ã© requisito da entrega, mas gostarÃ­amos de implemetar o upload de usuÃ¡rios pelo frontend/rota. TambÃ©m achamos que seria interessante adequar o status code retornado.

- Adicionar completamente type annotation.

- Refactor da rota v2_vision

## âœğŸ» Autores
- [PÃ¢mela Aliny Cleto Pavan](https://github.com/PamelaPavan)

